**Однослойный перцептрон. (моя реализация на JavaScript)**


1. Описание.
2. Распознавание.
3. Обучение.
4. [demo](https://bystrovleonid.github.io/) (надо обучить)

<hr>

1. Однослойный перцептрон - самая простая искуственная нейронная сеть.
Состоит из 1 слоя нейронов.<br>
Количество нейронов по количеству распознаваемых классов образов.<br>
На 1 вход подаётся либо 0 либо 1, входов может быть любое количество.<br>
Каждый нейрон имеет набор весов, по размеру равный количеству входов.<br>
Каждый вес - это число, до обучения это случайное вещественное число от 0 до 1.<br>
Каждый нейрон после обучения реагирует только на тот класс образов которому был обучен и не реагирует на любой другой из выборки.<br>
Количество выходов равно количеству распознаваемых классов образов.<br>
<br>
Пример:<br>
Нейронная сеть которая должна распознавать цифры от 0 до 9.<br>
На вход сети поступает чёрно-белое изображение 30x30 точек (массив из 900 точек в 1 изображении), на котором цифра от 0 до 9.<br>
Такая сеть должна содержать 10 нейронов, по одному нейрону на цифру.<br>
Каждый нейрон должен иметь 30x30 весов, т.е. массив из 900 весов.<br>
У сети 10 выходов, соответственно от 0 до 9.<br>
<br>
<br>
2. Распознавание.<br>
На вход сети поступают бинарные данные: нули и единицы.<br>
Эти данные поэлементно умножаются на веса нейрона и суммируются, это называется отклик нейрона.<br>
И так с каждым нейроном в сети.<br>
Ответ сети: выбирается тот класс образов на который был получен максимальныый отклик соответствующего нейрона.<br>
<br>
Пример:<br>
На вход сети поступает массив из 900 значений (нулей и единиц) назовём его I.<br>
Веса соответсвующих нейронов назовём W0 - W9.<br>
Для каждого нейрона соответсвующий вес нейрона умножается на значение массива и суммируется.<br>
Для нейрона 0 это S[0] = W0[1] * I[1] + ... + W0[900] * I[900],<br>
где W0[1] - первый элемент массива весов нейрона 0, а I[1] - первый элемент входного массива, W0[900] и I[900] соответсвенно последние элементы массивов.<br>
для нейрона 1 это S[1] = W1[1] * I[1] + ... + W1[900] * I[900],<br>
...<br>
для нейрона 9 это S[9] = W9[1] * I[1] + ... + W9[900] * I[900],<br>
Далее из массива сумм S[0] ... S[9] выбирается максимальная.<br>
Например максимальная сумма это S[0] - отклик нейрона 0, значит с большой долей вероятности если сеть была обучена правильно на входном изображении изображён 0.<br>
<br>
<br>
3. Обучение.<br>
На вход сети поступают бинарные данные: нули и единицы.<br>
Эти данные поэлементно умножаются на веса нейрона и суммируются, после суммирования применяется функция активации нейрона.<br>
Которая в однослойном перцептроне выглядит следующим образом:<br>
если сумма больше порога активации нейрона, то на выходе этого нейрона будет 1 иначе 0.<br>
Порог активации обычно 0.5<br>
Далее если нейрон дал неправильный ответ, его веса надо корректировать.<br>
Из правильного ответа вычитается ответ этого нейрона, это называется локальная ошибка сети (это будет -1 или 1, 0 - нет ошибки).<br>
Далее к каждому весовому коэффиценту нейрона прибавляется соответствующий элемент входных данных умноженный на локальную ошибку сети и умноженный на скорость обучения,<br>
где скорость обучения это число подбираемое вручную или иным образом.<br>
Веса корректируются для всех нейронов давших неправильные ответы.<br>
На каждой итерации обучения вычисляются локальные ошибки для каждого обучающего примера.<br>
Вычисляется глобальная ошибка сети, которая равна сумме абсолютных значений локальных ошибок сети, на одной итерации обучения.<br>
Обучение идёт пока глобальная ошибка больше нуля и прекращается когда глобальная ошибка равна нулю.<br>
<br>
Пример:<br>
На вход сети поступает массив из 900 значений (нулей и единиц) назовём его I.<br>
Веса соответсвующих нейронов назовём W0 - W9.<br>
Для каждого нейрона соответсвующий вес нейрона умножается на значение массива и суммируется.<br>
Для нейрона 0 это S[0] = W0[1] * I[1] + ... + W0[900] * I[900],<br>
где W0[1] - первый элемент массива весов нейрона 0, а I[1] - первый элемент входного массива, W0[900] и I[900] соответсвенно последние элементы массивов.<br>
далее применяется функция активации если S[0] > 0.5 то S[0] = 1 иначе S[0] = 0<br>
После вычисления ответа сети получается массив заполненный нулями и единицами длиной 10.<br>
Пусть на вход была подана картинка с изображением нуля.<br>
Тогда правильный ответ сети такой: S = [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]<br>
тогда пусть в качестве примера сеть выдала такой ответ: S = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]<br>
Ни один из нейронов не активировался а, должен был активироваться нейрон с индексом 0.<br>
Далее локальная ошибка сети будет 1 - 0 = 1. Для нейрона 0, для остальных нейронов ошибка равна нулю.<br>
Для нейрона 0, корректируем веса, пусть скорость обучения равна 0.01 тогда:<br>
W0[1] = W0[1] + I[1] * 1 * 0.01 - для весового коэффицента 1<br>
W0[2] = W0[2] + I[2] * 1 * 0.01 - для весового коэффицента 2<br>
...<br>
W0[900] = W0[900] + I[900] * 1 * 0.01 - для весового коэффицента 900<br>
Затем подаётся следующий пример из выборки, вычисляется ответ сети, вычисляются локальные ошибки, корректируются веса нейронов...<br>
Цикл продолжается до тех пор пока сеть не будет ошибаться на обучающей выборке, т.е. будет правильно распознавать все цифры из обучающей выборки.<br>
<br>
<br>
[demo](https://bystrovleonid.github.io/) (надо обучить)